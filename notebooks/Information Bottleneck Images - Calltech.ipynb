{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a984c13c-020b-4ddf-bb1f-5d189509d6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 22:37:39.448122: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-17 22:37:39.449237: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-17 22:37:39.455973: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-17 22:37:39.481604: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750199859.517070    2803 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750199859.525699    2803 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1750199859.555098    2803 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750199859.555135    2803 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750199859.555138    2803 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750199859.555140    2803 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-17 22:37:39.562990: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import layers, models, Model, losses\n",
    "from tensorflow.keras.applications import ResNet50V2, ResNet101V2\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ef36a1-d914-4bd8-94d9-954801493c76",
   "metadata": {},
   "source": [
    "# Carga de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b2ae071-cbfc-4ff5-b89a-f530fd501052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9144 files belonging to 102 classes.\n",
      "Using 7316 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 22:39:32.096005: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "raw_train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"../data/raw/calltech/caltech-101/caltech-101/101_ObjectCategories/101_ObjectCategories\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aec9f68c-15fe-4701-958c-5fcecfd9901b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9144 files belonging to 102 classes.\n",
      "Using 1828 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# Dataset de validación/test\n",
    "raw_test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"../data/raw/calltech/caltech-101/caltech-101/101_ObjectCategories/101_ObjectCategories\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d2beadd-7f11-4cfc-b6e2-9c48c5981a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = raw_train_ds.map(lambda x, y: (preprocess_input(x), y), num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)\n",
    "test_ds = raw_test_ds.map(lambda x, y: (preprocess_input(x), y), num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dae2d039-c899-42be-9ebb-43b78d35fa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = raw_train_ds.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9b51ffa-3c89-4bde-bf4e-a166fe603878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BACKGROUND_Google', 'Faces', 'Faces_easy', 'Leopards', 'Motorbikes', 'accordion', 'airplanes', 'anchor', 'ant', 'barrel', 'bass', 'beaver', 'binocular', 'bonsai', 'brain', 'brontosaurus', 'buddha', 'butterfly', 'camera', 'cannon', 'car_side', 'ceiling_fan', 'cellphone', 'chair', 'chandelier', 'cougar_body', 'cougar_face', 'crab', 'crayfish', 'crocodile', 'crocodile_head', 'cup', 'dalmatian', 'dollar_bill', 'dolphin', 'dragonfly', 'electric_guitar', 'elephant', 'emu', 'euphonium', 'ewer', 'ferry', 'flamingo', 'flamingo_head', 'garfield', 'gerenuk', 'gramophone', 'grand_piano', 'hawksbill', 'headphone', 'hedgehog', 'helicopter', 'ibis', 'inline_skate', 'joshua_tree', 'kangaroo', 'ketch', 'lamp', 'laptop', 'llama', 'lobster', 'lotus', 'mandolin', 'mayfly', 'menorah', 'metronome', 'minaret', 'nautilus', 'octopus', 'okapi', 'pagoda', 'panda', 'pigeon', 'pizza', 'platypus', 'pyramid', 'revolver', 'rhino', 'rooster', 'saxophone', 'schooner', 'scissors', 'scorpion', 'sea_horse', 'snoopy', 'soccer_ball', 'stapler', 'starfish', 'stegosaurus', 'stop_sign', 'strawberry', 'sunflower', 'tick', 'trilobite', 'umbrella', 'watch', 'water_lilly', 'wheelchair', 'wild_cat', 'windsor_chair', 'wrench', 'yin_yang']\n"
     ]
    }
   ],
   "source": [
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c71599f6-73f9-4fa3-9589-75265347c989",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.1),\n",
    "    tf.keras.layers.RandomZoom(0.1),\n",
    "])\n",
    "\n",
    "# Se aplica como parte del modelo o en el mapeo:\n",
    "train_ds = train_ds.map(lambda x, y: (data_augmentation(x, training=True), y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b79eb21-059a-40e6-8c14-47d32cd887b2",
   "metadata": {},
   "source": [
    "# Modelo Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db9ee719-60ae-4719-b4e0-150a4e60c3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo base\n",
    "#base_model = ResNet101V2(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "#base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d833eb9b-248f-45cc-8f41-6211d79987f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepIB(Model):\n",
    "    def __init__(self, z_dim, sampling=1, beta=1.0):\n",
    "        super(DeepIB, self).__init__()\n",
    "        self.sampling = sampling\n",
    "        self.beta = beta\n",
    "\n",
    "        self.base_model = ResNet101V2(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "        self.base_model.trainable = False\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder_x = tf.keras.Sequential([\n",
    "            tf.keras.Input(shape=(224, 224, 3)),\n",
    "            self.base_model,\n",
    "            layers.GlobalAveragePooling2D(),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(512, activation='relu'),\n",
    "            layers.Dropout(0.3)\n",
    "        ])\n",
    "        self.encoder_mu = layers.Dense(z_dim)\n",
    "        self.encoder_logvar = layers.Dense(z_dim)\n",
    "\n",
    "        # Decoder\n",
    "        self.decode_z = layers.Dense(len(class_names))  # Para clasificación en las clases\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = self.encoder_x(x)\n",
    "        mu = self.encoder_mu(x)\n",
    "        logvar = tf.clip_by_value(self.encoder_logvar(x), -10, 10)\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparametrize(self, mu, logvar):\n",
    "        eps_shape = tf.concat([tf.shape(mu), [self.sampling]], axis=0)\n",
    "        eps = tf.random.normal(eps_shape)\n",
    "        sigma = tf.exp(0.5 * logvar)\n",
    "        mu = tf.expand_dims(mu, -1)\n",
    "        sigma = tf.expand_dims(sigma, -1)\n",
    "        z = mu + sigma * eps\n",
    "        z = tf.transpose(z, perm=[0, 2, 1])  # [batch, samples, z_dim]\n",
    "        return z\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparametrize(mu, logvar)\n",
    "        y_pred = self.decode_z(z)  # [batch, samples, 10]\n",
    "        return y_pred, mu, logvar\n",
    "\n",
    "    def compute_loss(self, x, y_true):\n",
    "        y_pred, mu, logvar = self.call(x, training=True)\n",
    "        y_pred = tf.reduce_mean(y_pred, axis=1)  # Promedio sobre muestras\n",
    "        ce_loss = losses.SparseCategoricalCrossentropy(from_logits=True)(y_true, y_pred)\n",
    "        # KL divergence\n",
    "        var = tf.exp(logvar)\n",
    "        kl = -0.5 * tf.reduce_sum(1 + tf.math.log(var) - tf.square(mu) - var, axis=1)\n",
    "        _total_loss = tf.reduce_mean(ce_loss + self.beta * kl)\n",
    "        # Accuracy\n",
    "        _acc = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(y_pred, axis=1), tf.cast(y_true, tf.int64)), tf.float32))\n",
    "        return _total_loss, _acc\n",
    "\n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss, acc = self.compute_loss(x, y)\n",
    "        grads = tape.gradient(loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
    "        return {\"loss\": loss, \"accuracy\": acc}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        x, y = data\n",
    "        loss, acc = self.compute_loss(x, y)\n",
    "        return {\"loss\": loss, \"accuracy\": acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a74ebc4e-906a-4fec-83bd-fe9ced97e188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciar y entrenar el modelo\n",
    "model = DeepIB(z_dim=3, sampling=1, beta=1e-4)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fae46d1-df4d-40f8-b1e1-b39af11f195c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"deep_ib\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"deep_ib\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ resnet101v2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">42,626,560</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sequential_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">43,683,840</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,539</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,539</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">102</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">408</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ resnet101v2 (\u001b[38;5;33mFunctional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m42,626,560\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sequential_1 (\u001b[38;5;33mSequential\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │    \u001b[38;5;34m43,683,840\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │         \u001b[38;5;34m1,539\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │         \u001b[38;5;34m1,539\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m102\u001b[0m)         │           \u001b[38;5;34m408\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">43,687,326</span> (166.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m43,687,326\u001b[0m (166.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,056,670</span> (4.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,056,670\u001b[0m (4.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">42,630,656</span> (162.62 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m42,630,656\u001b[0m (162.62 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dummy_input = tf.keras.Input(shape=(224, 224, 3))\n",
    "output = model(dummy_input)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b20aca-6b08-46c8-93f7-f487147263f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"../models/deep_ib/checkpoints/weights_epoch_{epoch:02d}.weights.h5\",\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9434f195-1150-4739-b811-e6019956b631",
   "metadata": {},
   "source": [
    "# Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82441d7-a147-46cb-8fac-47e8b33cf668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m213/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1:26\u001b[0m 5s/step - accuracy: 0.3012 - loss: 2.9863"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds, epochs=10, validation_data=test_ds, )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3234c77-8e19-4c02-9423-ca332b3fe706",
   "metadata": {},
   "source": [
    "# Visualización de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca88f0a-27bf-45e8-924a-12730ed8e6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listas para almacenar las representaciones latentes y las etiquetas\n",
    "latents = []\n",
    "labels = []\n",
    "\n",
    "# Desactiva el entrenamiento para evitar muestreo aleatorio (usa solo mu)\n",
    "for x_batch, y_batch in test_ds:\n",
    "    mu, _ = model.encode(x_batch)\n",
    "    latents.append(mu.numpy())\n",
    "    labels.append(y_batch.numpy())\n",
    "\n",
    "# Concatenar todo en arrays\n",
    "latents = np.concatenate(latents, axis=0)  # (N, 2)\n",
    "labels = np.concatenate(labels, axis=0)    # (N,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcc6581-b122-42e0-a039-610c33c2fb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(latents[:, 0], latents[:, 1], c=labels, cmap='tab20', alpha=0.7, s=15)\n",
    "plt.colorbar(scatter, ticks=range(len(np.unique(labels))))\n",
    "plt.xlabel(\"z₁\")\n",
    "plt.ylabel(\"z₂\")\n",
    "plt.title(\"Espacio latente (mu) - Deep Information Bottleneck\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1213e285-d5bc-4453-8ac1-b2d213211046",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds, epochs=10, validation_data=test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f30a30-df1c-4946-affc-f00e1ed4c660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listas para almacenar las representaciones latentes y las etiquetas\n",
    "latents = []\n",
    "labels = []\n",
    "\n",
    "# Desactiva el entrenamiento para evitar muestreo aleatorio (usa solo mu)\n",
    "for x_batch, y_batch in test_ds:\n",
    "    mu, _ = model.encode(x_batch)\n",
    "    latents.append(mu.numpy())\n",
    "    labels.append(y_batch.numpy())\n",
    "\n",
    "# Concatenar todo en arrays\n",
    "latents = np.concatenate(latents, axis=0)  # (N, 2)\n",
    "labels = np.concatenate(labels, axis=0)    # (N,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c31bb4d-fc35-46e5-bbeb-58f063ab638e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(latents[:, 0], latents[:, 1], c=labels, cmap='tab20', alpha=0.7, s=15)\n",
    "plt.colorbar(scatter, ticks=range(len(np.unique(labels))))\n",
    "plt.xlabel(\"z₁\")\n",
    "plt.ylabel(\"z₂\")\n",
    "plt.title(\"Espacio latente (mu) - Deep Information Bottleneck\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f590a2-95d4-4213-8687-23a0c98891c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
